{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember: library imports are ALWAYS at the top of the script, no exceptions!\n",
    "import sqlite3\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context\n",
    "The data we will be using through the pratical classes comes from a small relational database whose schema can be seen below:\n",
    "![alt text](../figures/schema.png \"Relation database schema\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to database\n",
    "my_path = os.path.join(\"..\", \"data\", \"datamining.db\")\n",
    "\n",
    "# connect to the database\n",
    "conn = sqlite3.connect(my_path)\n",
    "\n",
    "# the query\n",
    "query = \"\"\"\n",
    "select\n",
    "    age, \n",
    "    income, \n",
    "    frq, \n",
    "    rcn, \n",
    "    mnt, \n",
    "    clothes, \n",
    "    kitchen, \n",
    "    small_appliances, \n",
    "    toys, \n",
    "    house_keeping,\n",
    "    dependents, \n",
    "    per_net_purchase,\n",
    "    g.gender, \n",
    "    e.education, \n",
    "    m.status, \n",
    "    r.description\n",
    "from customers as c\n",
    "    join genders as g on g.id = c.gender_id\n",
    "    join education_levels as e on e.id = c.education_id\n",
    "    join marital_status as m on m.id = c.marital_status_id\n",
    "    join recommendations as r on r.id = c.recommendation_id\n",
    "order by c.id;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a copy of your original dataset\n",
    "\n",
    "why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata\n",
    "- *id* - The unique identifier of the customer\n",
    "- *age* - The year of birht of the customer\n",
    "- *income* - The income of the customer\n",
    "- *frq* - Frequency: number of purchases made by the customer\n",
    "- *rcn* - Recency: number of days since last customer purchase\n",
    "- *mnt* - Monetary: amount of € spent by the customer in purchases\n",
    "- *clothes* - Number of clothes items purchased by the customer\n",
    "- *kitchen* - Number of kitchen items purchased by the customer\n",
    "- *small_appliances* - Number of small_appliances items purchased by the customer\n",
    "- *toys* - Number of toys items purchased by the customer\n",
    "- *house_keeping* - Number of house_keeping items purchased by the customer\n",
    "- *dependents* - Binary. Whether or not the customer has dependents\n",
    "- *per_net_purchase* - Percentage of purchases made online\n",
    "- *education* - Education level of the customer\n",
    "- *status* - Marital status of the customer\n",
    "- *gender* - Gender of the customer\n",
    "- *description* - Last customer's recommendation description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems:\n",
    "- Duplicates?\n",
    "- Data types?\n",
    "- Missing values?\n",
    "- Strange values?\n",
    "- Descriptive statistics?\n",
    "\n",
    "### Take a closer look and point out possible problems:\n",
    "\n",
    "(hint: a missing values in pandas is represented with a NaN value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace \"\" by nans\n",
    "df.replace(\"\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                   int64\n",
       "income              float64\n",
       "frq                   int64\n",
       "rcn                   int64\n",
       "mnt                   int64\n",
       "clothes               int64\n",
       "kitchen               int64\n",
       "small_appliances      int64\n",
       "toys                  int64\n",
       "house_keeping         int64\n",
       "dependents          float64\n",
       "per_net_purchase      int64\n",
       "gender               object\n",
       "education            object\n",
       "status               object\n",
       "description          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check dataset data types again\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>8998.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1966.05968</td>\n",
       "      <td>17.296552</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1966.0</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>1996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>8952.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69963.550827</td>\n",
       "      <td>27591.556226</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>47741.0</td>\n",
       "      <td>70030.5</td>\n",
       "      <td>92218.0</td>\n",
       "      <td>140628.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frq</th>\n",
       "      <td>8998.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.848077</td>\n",
       "      <td>10.903435</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rcn</th>\n",
       "      <td>8998.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.469771</td>\n",
       "      <td>69.761802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>549.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnt</th>\n",
       "      <td>8998.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>622.162814</td>\n",
       "      <td>646.768205</td>\n",
       "      <td>6.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>3052.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothes</th>\n",
       "      <td>8998.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.446655</td>\n",
       "      <td>23.422249</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kitchen</th>\n",
       "      <td>8998.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.039675</td>\n",
       "      <td>7.848139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>small_appliances</th>\n",
       "      <td>8998.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.524116</td>\n",
       "      <td>12.586437</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toys</th>\n",
       "      <td>8998.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.036897</td>\n",
       "      <td>7.924422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house_keeping</th>\n",
       "      <td>8998.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.929984</td>\n",
       "      <td>7.882655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dependents</th>\n",
       "      <td>8716.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.707205</td>\n",
       "      <td>0.455071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per_net_purchase</th>\n",
       "      <td>8998.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.428984</td>\n",
       "      <td>18.495742</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>8998</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>5784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>8951</td>\n",
       "      <td>6</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>4429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <td>8821</td>\n",
       "      <td>6</td>\n",
       "      <td>Married</td>\n",
       "      <td>3273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>8998</td>\n",
       "      <td>5</td>\n",
       "      <td>OK nice!</td>\n",
       "      <td>3434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count unique         top  freq          mean           std  \\\n",
       "age               8998.0    NaN         NaN   NaN    1966.05968     17.296552   \n",
       "income            8952.0    NaN         NaN   NaN  69963.550827  27591.556226   \n",
       "frq               8998.0    NaN         NaN   NaN     19.848077     10.903435   \n",
       "rcn               8998.0    NaN         NaN   NaN     62.469771     69.761802   \n",
       "mnt               8998.0    NaN         NaN   NaN    622.162814    646.768205   \n",
       "clothes           8998.0    NaN         NaN   NaN     50.446655     23.422249   \n",
       "kitchen           8998.0    NaN         NaN   NaN      7.039675      7.848139   \n",
       "small_appliances  8998.0    NaN         NaN   NaN     28.524116     12.586437   \n",
       "toys              8998.0    NaN         NaN   NaN      7.036897      7.924422   \n",
       "house_keeping     8998.0    NaN         NaN   NaN      6.929984      7.882655   \n",
       "dependents        8716.0    NaN         NaN   NaN      0.707205      0.455071   \n",
       "per_net_purchase  8998.0    NaN         NaN   NaN     42.428984     18.495742   \n",
       "gender              8998      2           M  5784           NaN           NaN   \n",
       "education           8951      6  Graduation  4429           NaN           NaN   \n",
       "status              8821      6     Married  3273           NaN           NaN   \n",
       "description         8998      5    OK nice!  3434           NaN           NaN   \n",
       "\n",
       "                      min      25%      50%      75%       max  \n",
       "age                1936.0   1951.0   1966.0   1981.0    1996.0  \n",
       "income            10000.0  47741.0  70030.5  92218.0  140628.0  \n",
       "frq                   3.0     10.0     17.0     28.0      59.0  \n",
       "rcn                   0.0     26.0     53.0     79.0     549.0  \n",
       "mnt                   6.0     63.0    383.0   1076.0    3052.0  \n",
       "clothes               1.0     33.0     51.0     69.0      99.0  \n",
       "kitchen               0.0      2.0      4.0     10.0      75.0  \n",
       "small_appliances      1.0     19.0     28.0     37.0      74.0  \n",
       "toys                  0.0      2.0      4.0     10.0      62.0  \n",
       "house_keeping         0.0      2.0      4.0      9.0      77.0  \n",
       "dependents            0.0      0.0      1.0      1.0       1.0  \n",
       "per_net_purchase      4.0     28.0     45.0     57.0      88.0  \n",
       "gender                NaN      NaN      NaN      NaN       NaN  \n",
       "education             NaN      NaN      NaN      NaN       NaN  \n",
       "status                NaN      NaN      NaN      NaN       NaN  \n",
       "description           NaN      NaN      NaN      NaN       NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check descriptive statistics again\n",
    "df.describe(include=\"all\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metric and non-metric features. Why?\n",
    "non_metric_features = [\"education\", \"status\", \"gender\", \"dependents\", \"description\"]\n",
    "metric_features = df.columns.drop(non_metric_features).to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill missing values (Data imputation)\n",
    "\n",
    "How can we fill missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy to apply central tendency measures imputation\n",
    "df_central = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                   0\n",
       "income               46\n",
       "frq                   0\n",
       "rcn                   0\n",
       "mnt                   0\n",
       "clothes               0\n",
       "kitchen               0\n",
       "small_appliances      0\n",
       "toys                  0\n",
       "house_keeping         0\n",
       "dependents          282\n",
       "per_net_purchase      0\n",
       "gender                0\n",
       "education            47\n",
       "status              177\n",
       "description           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count of missing values\n",
    "df_central.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/66/vxt1mdgd1nb22lh849h7f82m0000gn/T/ipykernel_64873/1469541937.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_central.median()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age                  1966.0\n",
       "income              70030.5\n",
       "frq                    17.0\n",
       "rcn                    53.0\n",
       "mnt                   383.0\n",
       "clothes                51.0\n",
       "kitchen                 4.0\n",
       "small_appliances       28.0\n",
       "toys                    4.0\n",
       "house_keeping           4.0\n",
       "dependents              1.0\n",
       "per_net_purchase       45.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_central.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education      Graduation\n",
       "status            Married\n",
       "gender                  M\n",
       "dependents            1.0\n",
       "description      OK nice!\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modes = df_central[non_metric_features].mode().loc[0]\n",
    "modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/66/vxt1mdgd1nb22lh849h7f82m0000gn/T/ipykernel_64873/2302810431.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_central.fillna(df_central.median(), inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age                 0\n",
       "income              0\n",
       "frq                 0\n",
       "rcn                 0\n",
       "mnt                 0\n",
       "clothes             0\n",
       "kitchen             0\n",
       "small_appliances    0\n",
       "toys                0\n",
       "house_keeping       0\n",
       "dependents          0\n",
       "per_net_purchase    0\n",
       "gender              0\n",
       "education           0\n",
       "status              0\n",
       "description         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_central.fillna(df_central.median(), inplace=True)\n",
    "df_central.fillna(modes, inplace=True)\n",
    "df_central.isna().sum()  # checking how many NaNs we still have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new df copy to explore neighbordhood imputation\n",
    "df_neighbors = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>frq</th>\n",
       "      <th>rcn</th>\n",
       "      <th>mnt</th>\n",
       "      <th>clothes</th>\n",
       "      <th>kitchen</th>\n",
       "      <th>small_appliances</th>\n",
       "      <th>toys</th>\n",
       "      <th>house_keeping</th>\n",
       "      <th>dependents</th>\n",
       "      <th>per_net_purchase</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>status</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1955</td>\n",
       "      <td>93571.0</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>888</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>Master</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK nice!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>90</td>\n",
       "      <td>184</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59</td>\n",
       "      <td>F</td>\n",
       "      <td>2nd Cycle</td>\n",
       "      <td>Married</td>\n",
       "      <td>Meh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1981</td>\n",
       "      <td>60457.0</td>\n",
       "      <td>9</td>\n",
       "      <td>73</td>\n",
       "      <td>63</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57</td>\n",
       "      <td>M</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Married</td>\n",
       "      <td>Meh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1944</td>\n",
       "      <td>116259.0</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>1279</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>M</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK nice!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1967</td>\n",
       "      <td>75274.0</td>\n",
       "      <td>16</td>\n",
       "      <td>67</td>\n",
       "      <td>263</td>\n",
       "      <td>88</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66</td>\n",
       "      <td>M</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>Kind of OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8932</th>\n",
       "      <td>1959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>71</td>\n",
       "      <td>716</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>M</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Married</td>\n",
       "      <td>Meh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8942</th>\n",
       "      <td>1950</td>\n",
       "      <td>92746.0</td>\n",
       "      <td>34</td>\n",
       "      <td>98</td>\n",
       "      <td>1399</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>M</td>\n",
       "      <td>Master</td>\n",
       "      <td>Married</td>\n",
       "      <td>Take my money!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8964</th>\n",
       "      <td>1978</td>\n",
       "      <td>44661.0</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42</td>\n",
       "      <td>M</td>\n",
       "      <td>1st Cycle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK nice!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8972</th>\n",
       "      <td>1976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>254</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59</td>\n",
       "      <td>M</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Meh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8992</th>\n",
       "      <td>1954</td>\n",
       "      <td>87399.0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>837</td>\n",
       "      <td>56</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Married</td>\n",
       "      <td>Kind of OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>542 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age    income  frq  rcn   mnt  clothes  kitchen  small_appliances  \\\n",
       "3     1955   93571.0   26   10   888       60       10                19   \n",
       "61    1968       NaN   14   90   184       95        1                 3   \n",
       "67    1981   60457.0    9   73    63       37        2                51   \n",
       "70    1944  116259.0   28   35  1279       17        6                54   \n",
       "73    1967   75274.0   16   67   263       88        3                 6   \n",
       "...    ...       ...  ...  ...   ...      ...      ...               ...   \n",
       "8932  1959       NaN   20   71   716       67        5                25   \n",
       "8942  1950   92746.0   34   98  1399       50        5                36   \n",
       "8964  1978   44661.0    6   49    33       18       18                35   \n",
       "8972  1976       NaN   17    9   254       70        1                28   \n",
       "8992  1954   87399.0   25    1   837       56        8                27   \n",
       "\n",
       "      toys  house_keeping  dependents  per_net_purchase gender   education  \\\n",
       "3        6              5         1.0                35      F      Master   \n",
       "61       1              0         1.0                59      F   2nd Cycle   \n",
       "67       6              3         NaN                57      M         PhD   \n",
       "70       3             20         0.0                11      M  Graduation   \n",
       "73       1              2         NaN                66      M  Graduation   \n",
       "...    ...            ...         ...               ...    ...         ...   \n",
       "8932     3              1         0.0                27      M  Graduation   \n",
       "8942     5              4         NaN                28      M      Master   \n",
       "8964    16             13         1.0                42      M   1st Cycle   \n",
       "8972     1              1         1.0                59      M  Graduation   \n",
       "8992     8              1         NaN                47      M  Graduation   \n",
       "\n",
       "        status      description  \n",
       "3          NaN         OK nice!  \n",
       "61     Married           Meh...  \n",
       "67     Married           Meh...  \n",
       "70         NaN         OK nice!  \n",
       "73      Single       Kind of OK  \n",
       "...        ...              ...  \n",
       "8932   Married           Meh...  \n",
       "8942   Married  Take my money!!  \n",
       "8964       NaN         OK nice!  \n",
       "8972  Divorced           Meh...  \n",
       "8992   Married       Kind of OK  \n",
       "\n",
       "[542 rows x 16 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeing rows with NaNs\n",
    "nans_index = df_neighbors.isna().any(axis=1)\n",
    "df_neighbors[nans_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# KNNImputer - only works for numerical varaibles\n",
    "imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "df_neighbors[metric_features] = imputer.fit_transform(df_neighbors[metric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>frq</th>\n",
       "      <th>rcn</th>\n",
       "      <th>mnt</th>\n",
       "      <th>clothes</th>\n",
       "      <th>kitchen</th>\n",
       "      <th>small_appliances</th>\n",
       "      <th>toys</th>\n",
       "      <th>house_keeping</th>\n",
       "      <th>per_net_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1955.0</td>\n",
       "      <td>93571.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>888.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1968.0</td>\n",
       "      <td>63143.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1981.0</td>\n",
       "      <td>60457.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1944.0</td>\n",
       "      <td>116259.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1279.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1967.0</td>\n",
       "      <td>75274.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8932</th>\n",
       "      <td>1959.0</td>\n",
       "      <td>85643.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>716.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8942</th>\n",
       "      <td>1950.0</td>\n",
       "      <td>92746.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1399.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8964</th>\n",
       "      <td>1978.0</td>\n",
       "      <td>44661.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8972</th>\n",
       "      <td>1976.0</td>\n",
       "      <td>63932.4</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8992</th>\n",
       "      <td>1954.0</td>\n",
       "      <td>87399.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>542 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         age    income   frq   rcn     mnt  clothes  kitchen  \\\n",
       "3     1955.0   93571.0  26.0  10.0   888.0     60.0     10.0   \n",
       "61    1968.0   63143.0  14.0  90.0   184.0     95.0      1.0   \n",
       "67    1981.0   60457.0   9.0  73.0    63.0     37.0      2.0   \n",
       "70    1944.0  116259.0  28.0  35.0  1279.0     17.0      6.0   \n",
       "73    1967.0   75274.0  16.0  67.0   263.0     88.0      3.0   \n",
       "...      ...       ...   ...   ...     ...      ...      ...   \n",
       "8932  1959.0   85643.4  20.0  71.0   716.0     67.0      5.0   \n",
       "8942  1950.0   92746.0  34.0  98.0  1399.0     50.0      5.0   \n",
       "8964  1978.0   44661.0   6.0  49.0    33.0     18.0     18.0   \n",
       "8972  1976.0   63932.4  17.0   9.0   254.0     70.0      1.0   \n",
       "8992  1954.0   87399.0  25.0   1.0   837.0     56.0      8.0   \n",
       "\n",
       "      small_appliances  toys  house_keeping  per_net_purchase  \n",
       "3                 19.0   6.0            5.0              35.0  \n",
       "61                 3.0   1.0            0.0              59.0  \n",
       "67                51.0   6.0            3.0              57.0  \n",
       "70                54.0   3.0           20.0              11.0  \n",
       "73                 6.0   1.0            2.0              66.0  \n",
       "...                ...   ...            ...               ...  \n",
       "8932              25.0   3.0            1.0              27.0  \n",
       "8942              36.0   5.0            4.0              28.0  \n",
       "8964              35.0  16.0           13.0              42.0  \n",
       "8972              28.0   1.0            1.0              59.0  \n",
       "8992              27.0   8.0            1.0              47.0  \n",
       "\n",
       "[542 rows x 11 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See rows with NaNs imputed\n",
    "df_neighbors.loc[nans_index, metric_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's keep the central imputation\n",
    "df = df_central.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An overview of our previous data exploration\n",
    "\n",
    "You can also explore this dataset using the exported `pandas-profiling` report.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../figures/exp_analysis/categorical_variables_frequecies.png)\n",
    "\n",
    "![](../figures/exp_analysis/numeric_variables_histograms.png)\n",
    "\n",
    "![](../figures/exp_analysis/numeric_variables_boxplots.png)\n",
    "\n",
    "![](../figures/exp_analysis/pairwise_relationship_of_numerical_variables.png)\n",
    "\n",
    "![](../figures/exp_analysis/correlation_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier removal\n",
    "\n",
    "Why do we need to remove outliers? Which methods can we use?\n",
    "\n",
    "\n",
    "Let's start by \"manually\" filtering the dataset's outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This may vary from session to session, and is prone to varying interpretations.\n",
    "# A simple example is provided below:\n",
    "\n",
    "filters1 = (\n",
    "    (df['house_keeping']<=50)\n",
    "    &\n",
    "    (df['kitchen']<=40)\n",
    "    &\n",
    "    (df['toys']<=35)\n",
    "    &\n",
    "    (df['education']!='OldSchool')\n",
    ")\n",
    "\n",
    "df_1 = df[filters1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of data kept after removing outliers: 0.9799\n"
     ]
    }
   ],
   "source": [
    "print('Percentage of data kept after removing outliers:', np.round(df_1.shape[0] / df_original.shape[0], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier removal using only the IQR method\n",
    "\n",
    "Why should you use/not use this method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of data kept after removing outliers: 0.8242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/66/vxt1mdgd1nb22lh849h7f82m0000gn/T/ipykernel_64873/3733093585.py:12: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
      "  filters2.append(df[metric].between(llim, ulim, inclusive=True))\n"
     ]
    }
   ],
   "source": [
    "q25 = df.quantile(.25)\n",
    "q75 = df.quantile(.75)\n",
    "iqr = (q75 - q25)\n",
    "\n",
    "upper_lim = q75 + 1.5 * iqr\n",
    "lower_lim = q25 - 1.5 * iqr\n",
    "\n",
    "filters2 = []\n",
    "for metric in metric_features:\n",
    "    llim = lower_lim[metric]\n",
    "    ulim = upper_lim[metric]\n",
    "    filters2.append(df[metric].between(llim, ulim, inclusive=True))\n",
    "\n",
    "filters2 = pd.Series(np.all(filters2, 0))\n",
    "df_2 = df[filters2]\n",
    "print('Percentage of data kept after removing outliers:', np.round(df_2.shape[0] / df_original.shape[0], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think about this percentage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining different outlier methods\n",
    "\n",
    "More robust/ consistent outlier detection method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of data kept after removing outliers: 0.9819\n"
     ]
    }
   ],
   "source": [
    "df_3 = df[(filters1 | filters2)]\n",
    "print('Percentage of data kept after removing outliers:', np.round(df_3.shape[0] / df_original.shape[0], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the manual filtering version\n",
    "df = df_1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "A reminder of our metadata:\n",
    "- *id* - The unique identifier of the customer\n",
    "- *age* - The year of birht of the customer\n",
    "- *income* - The income of the customer\n",
    "- *frq* - Frequency: number of purchases made by the customer\n",
    "- *rcn* - Recency: number of days since last customer purchase\n",
    "- *mnt* - Monetary: amount of € spent by the customer in purchases\n",
    "- *clothes* - Number of clothes items purchased by the customer\n",
    "- *kitchen* - Number of kitchen items purchased by the customer\n",
    "- *small_appliances* - Number of small_appliances items purchased by the customer\n",
    "- *toys* - Number of toys items purchased by the customer\n",
    "- *house_keeping* - Number of house_keeping items purchased by the customer\n",
    "- *dependents* - Binary. Whether or not the customer has dependents\n",
    "- *per_net_purchase* - Percentage of purchases made online\n",
    "- *education* - Education level of the customer\n",
    "- *status* - Marital status of the customer\n",
    "- *gender* - Gender of the customer\n",
    "- *description* - Last customer's recommendation description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'birth_year'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/ProgrammingClass/lib/python3.10/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ProgrammingClass/lib/python3.10/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ProgrammingClass/lib/python3.10/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'birth_year'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create the \"birth_year\" and change the \"age\" variable. \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Also, create a new variable \"spent_online\": amount of € spent by the customer in online purchases\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# CODE HERE\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#df.rename(columns={'age': 'birth_year'}, inplace=True)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2016\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbirth_year\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m df\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ProgrammingClass/lib/python3.10/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ProgrammingClass/lib/python3.10/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'birth_year'"
     ]
    }
   ],
   "source": [
    "# Create the \"birth_year\" and change the \"age\" variable. \n",
    "# Also, create a new variable \"spent_online\": amount of € spent by the customer in online purchases\n",
    "# CODE HERE\n",
    "#df.rename(columns={'age': 'birth_year'}, inplace=True)\n",
    "df['age'] = 2016 - df['birth_year']\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How can we avoid having as many extreme values in 'rcn' (look at distribution)? (Discuss)\n",
    "print((df['rcn']>100).value_counts())\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable selection: Redundancy VS Relevancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redundancy\n",
    "We already saw our original correlation matrix:\n",
    "![](../figures/exp_analysis/correlation_matrix.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop variables according to their correlations\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating metric_features\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevancy\n",
    "Selecting variables based on the relevancy of each one to the task. Example: remove uncorrelated variables with the target, stepwise regression, use variables for product clustering, use variables for socio-demographic clustering, ...\n",
    "\n",
    "Variables that aren't correlated with any other variable are often also not relevant. In this case we will not focus on this a lot since we don't have a defined task yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization\n",
    "\n",
    "Why do we scale our data? Discuss!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minmax = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use MinMaxScaler to scale the data\n",
    "scaler = # CODE HERE\n",
    "scaled_feat = # CODE HERE\n",
    "scaled_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what the fit method is doing (notice the trailing underscore):\n",
    "print(\"Parameters fitted:\\n\", scaler.data_min_, \"\\n\", scaler.data_max_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minmax[metric_features] = scaled_feat\n",
    "df_minmax.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out what characteristics the MinMaxed data have\n",
    "df_minmax[metric_features].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_standard = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use StandardScaler to scale the data\n",
    "scaler =  # CODE HERE\n",
    "scaled_feat =  # CODE HERE\n",
    "scaled_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# See what the fit method is doing (notice the trailing underscore):\n",
    "print(\"Parameters fitted:\\n\", scaler.mean_, \"\\n\", scaler.var_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_standard[metric_features] = scaled_feat\n",
    "df_standard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out what characteristics the Standardized data have\n",
    "df_standard[metric_features].describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: What if we had a training and validation/test set? Should we fit a Scaler in both? What about other Sklearn objects?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_standard.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohc = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's remove status=Whatever\n",
    "df_ohc.loc[df_ohc['status'] == 'Whatever', 'status'] = df['status'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use OneHotEncoder to encode the categorical features. Get feature names and create a DataFrame \n",
    "# with the one-hot encoded categorical features (pass feature names)\n",
    "ohc = OneHotEncoder(sparse=False, drop=\"first\")\n",
    "ohc_feat = # CODE HERE\n",
    "ohc_feat_names = # CODE HERE\n",
    "ohc_df = # CODE HERE (watch out about row index)\n",
    "ohc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reassigning df to contain ohc variables\n",
    "df_ohc = pd.concat([df_ohc.drop(columns=non_metric_features), ohc_df], axis=1)\n",
    "df_ohc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_ohc.copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
